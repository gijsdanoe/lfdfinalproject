{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "final_project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8VATzuCGCbL"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "\n",
        "'''This program reads in the train and test data, adds bigrams, POS-tags and performs TF-IDF, then trains on the data and predicts on the test set using an SVM. It outputs the most informative features and an evaluation matrix.'''\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import time\n",
        "import nltk\n",
        "# following data needs to be downloaded at first iteration only\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import string\n",
        "import csv\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import spacy\n",
        "\n",
        "\n",
        "# paths\n",
        "train_file_OD = '/content/gdrive/MyDrive/lfd-project-data/trainOD.csv'\n",
        "\n",
        "train_file_ID = '/content/gdrive/MyDrive/lfd-project-data/trainID.csv'\n",
        "dev_file_ID = '/content/gdrive/MyDrive/lfd-project-data/devID.csv'\n",
        "test_file_ID = '/content/gdrive/MyDrive/lfd-project-data/testID.csv'\n",
        "\n",
        "test_trump = '/content/gdrive/MyDrive/lfd-project-data/testtrump.csv'\n",
        "test_police = '/content/gdrive/MyDrive/lfd-project-data/testpolice.csv'\n",
        "test_education = '/content/gdrive/MyDrive/lfd-project-data/testeducation.csv'\n",
        "test_immigration = '/content/gdrive/MyDrive/lfd-project-data/testimmigration.csv'\n",
        "test_economy = '/content/gdrive/MyDrive/lfd-project-data/testeconomy.csv'\n",
        "\n",
        "\n",
        "def read_corpus(corpus_file, pos_tag):\n",
        "    '''splits line in tokens, appends the text of each review to a list.'''\n",
        "    \n",
        "    documents = []\n",
        "    labels = []\n",
        "    with open(corpus_file, encoding='utf-8', errors='ignore') as f:\n",
        "        reader = csv.reader(f, delimiter=',')\n",
        "        for line in reader:\n",
        "            # remove give-away features\n",
        "            new_line = line[0].replace('timescontent.com', '').replace('MATP', '').replace('Reprint', '').replace('â€', '' ).replace('â€¢', '').replace('Â', '').replace('™', '').replace('Herald', '')\n",
        "            \n",
        "            tokens = new_line.strip().split()\n",
        "            \n",
        "            # tokenize and then filter punctuation\n",
        "            tokens = nltk.word_tokenize(line)\n",
        "            tokens = list(filter(lambda token: token not in string.punctuation, tokens))\n",
        "\n",
        "            if pos_tag:\n",
        "                #POS-tags\n",
        "                pos = nltk_pos(tokens)\n",
        "                for tag in pos:\n",
        "                    tokens.append(tag)\n",
        "            documents.append(tokens)\n",
        "            labels.append(line[-1])\n",
        "    return documents, labels\n",
        "\n",
        "\n",
        "def identity(x):\n",
        "    '''Dummy function that just returns the input'''\n",
        "    return x\n",
        "\n",
        "\n",
        "def plot_coefficients(classifier, feature_names, top_features=40):\n",
        "    coef = classifier.coef_.ravel()\n",
        "    top_positive_coefficients = np.argsort(coef)[-top_features:]\n",
        "    top_negative_coefficients = np.argsort(coef)[:top_features]\n",
        "    top_coefficients = np.hstack([top_negative_coefficients, top_positive_coefficients])\n",
        "    print(classifier.classes_)\n",
        "    # create plot\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    colors = ['red' if c < 0 else 'blue' for c in coef[top_coefficients]]\n",
        "    plt.bar(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
        "    feature_names = np.array(feature_names)\n",
        "    plt.xticks(np.arange(1, 1 + 2 * top_features), feature_names[top_coefficients], rotation=60, ha='right')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def nltk_pos(txt):\n",
        "    pos = nltk.pos_tag(txt)\n",
        "    return [token[1] for token in pos]\n",
        "\n",
        "def grid_search():\n",
        "    # Grid search\n",
        "    param_grid = {'C': [0.1,1, 10], 'gamma': ['scale','auto'],'kernel': ['linear', 'rbf', 'poly', 'sigmoid']}\n",
        "    grid = GridSearchCV(svm.SVC(),param_grid,refit=True,verbose=2)\n",
        "    grid_classifier = Pipeline([('vec', vec), ('cls', grid)])\n",
        "    grid_classifier.fit(X_train,Y_train)\n",
        "    print(grid.best_params_)\n",
        "    grid_predictions = grid_classifier.predict(X_test)\n",
        "    print(classification_report(Y_test,grid_predictions))\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    #edit these parameters according to preference.\n",
        "    gridsearch = False\n",
        "    postags = False\n",
        "    min_ngram = 1\n",
        "    max_ngram = 1\n",
        "\n",
        "    # reads in the full input texts with their corresponding labels. Change files to test different datasets\n",
        "    X_train, Y_train = read_corpus(train_file_OD, postags)\n",
        "    X_test, Y_test = read_corpus(test_file_ID, postags)\n",
        "\n",
        "    if gridsearch:\n",
        "        grid_search()\n",
        "    else:\n",
        "        # Convert the texts to vectors\n",
        "        vec = TfidfVectorizer(preprocessor=identity, tokenizer=identity, ngram_range=(min_ngram,max_ngram))\n",
        "        vec.fit(X_train)\n",
        "    \n",
        "        # Combine the vectorizer with a Support Vector Machine classifier\n",
        "        X_train = vec.transform(X_train)\n",
        "        clf = svm.LinearSVC()    \n",
        "        pipe = Pipeline([('vec', vec), ('cls', clf)])\n",
        "        # trains the classifier with the training features and labels, measures time it takes to train\n",
        "        classifier = clf.fit(X_train, Y_train)\n",
        "        plot_coefficients(classifier, vec.get_feature_names())\n",
        "\n",
        "        # lets the trained classifier predict labels for the test set\n",
        "        Y_pred = pipe.predict(X_test)\n",
        "    \n",
        "        # calculate metrics\n",
        "        print(classification_report(Y_test, Y_pred, digits=3)) \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}